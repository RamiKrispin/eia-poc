{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: EIA API - US48 Demand for Electricity Backfill\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "---"
      ],
      "id": "2edbc918"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of this doc is to execute an initial data pull of the demand for electricity in the US (lower 48) from the EIA API. This includes the following functionality:\n",
        "\n",
        "- Setting parameters and pulling the data\n",
        "- Data quality checks\n",
        "- Saving the data and creating a log file\n",
        "- Data profiling\n",
        "\n",
        "## Load libraries\n",
        "\n",
        "We will pull the data from the EIA API using a set of functions on the `eia_api.py` file. This includes the following functions:\n",
        "\n",
        "- `eia_get` - A function for query data from the API. Can pull up to 5000 rows per call\n",
        "- `eia_backfile` - A wrapper function, using batches requests from the API using the `eia_get` function to serve large requests (more than 5000 rows)\n",
        "- `day_offset` - A helper function creates a vector of dates equally spaced by days\n",
        "- `hour_offset` - A helper function creates a vector of dates equally spaced by days\n"
      ],
      "id": "b2102f51"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import eia_api\n",
        "import plot_fc\n",
        "import eia_etl as etl\n",
        "import eia_forecast as fc"
      ],
      "id": "7bb1ba52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `eia_api.py` file imports the following libraries:\n",
        "\n",
        "- `pandas` - for data processing\n",
        "- `datetime` - to work with dates and time objects\n",
        "- `requests` - to send `GET` requests to the EIA API\n",
        "\n",
        "In addition, we will use the following libraries:\n",
        "\n",
        "- `os` - load environment variables\n",
        "- `numpy` - to create sequences (vectors)\n",
        "- `plotly` - visualize the data\n",
        "- `pathlib` - set file path\n",
        "- `ydata_profiling` - for data profiling\n"
      ],
      "id": "f949b458"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from pathlib import Path\n",
        "from ydata_profiling import ProfileReport\n",
        "from darts import TimeSeries\n",
        "from darts.models.forecasting.linear_regression_model import LinearRegressionModel"
      ],
      "id": "72c15ea0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Parameters\n",
        "\n",
        "Next, we will set the backfile parameters:"
      ],
      "id": "ea92cfc5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "api_path = \"electricity/rto/region-data/data\"\n",
        "facets = {\n",
        "    \"respondent\": \"US48\",\n",
        "    \"type\": \"D\"\n",
        "}\n",
        "\n",
        "start = datetime.datetime(2015, 7, 1, 5)\n",
        "end = datetime.datetime(2024, 3, 8, 1)\n",
        "\n",
        "offset = 2250"
      ],
      "id": "afbb5353",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the `getenv` function from the `os` library to pull the EIA API key, which is stored as an environment variable named `EIA_API_KEY`:\n"
      ],
      "id": "40416453"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "eia_api_key = os.getenv('EIA_API_KEY')"
      ],
      "id": "3ed0bc22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the `eia_metadata` function to pull the series metadata. Note that to pull metadata from the API, we will use as the `api_path` the series routh path and drop the `/data` extension (which is used to pull data):\n"
      ],
      "id": "72fffa3e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metadata = eia_api.eia_metadata(api_key = eia_api_key, api_path = \"electricity/rto/region-data/\")"
      ],
      "id": "0458a961",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Depending on the API path, the API returns some useful information about the series available on the path:\n"
      ],
      "id": "bd7cc08f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metadata.meta.keys()"
      ],
      "id": "486c8acb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One useful data point is the start and end period of the series:\n"
      ],
      "id": "b657c83c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(metadata.meta[\"startPeriod\"])\n",
        "print(metadata.meta[\"endPeriod\"])"
      ],
      "id": "6f221083",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pulling the Data\n",
        "\n",
        "By default, the API has a 5000-row limitation per pull. The eia_backfill function enables the handling of a larger data request by sending a batch request and appending back the data:\n"
      ],
      "id": "b9576d72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = eia_api.eia_backfile(api_key = eia_api_key, \n",
        "        api_path = api_path, \n",
        "        facets = facets, \n",
        "        start = start,\n",
        "        end = end,\n",
        "        offset = offset) "
      ],
      "id": "2377b036",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The DataFrame head:"
      ],
      "id": "7b9e3917"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.data.head(10)"
      ],
      "id": "549c868f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And, the DataFrame tail:"
      ],
      "id": "efc13d5d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.data.tail(10)"
      ],
      "id": "6cf5e3b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Quality checks\n",
        "\n",
        "We will runn the following data quality checks:\n",
        "\n",
        "- Check that the series timestamp is regular (e.g., equaliy spaced)\n",
        "- Check for missing values\n",
        "- Check for match between the start and end of the series and the request settings\n",
        "- Create a log file \n",
        "\n",
        "### Check the Series Timestamp\n"
      ],
      "id": "c580c4f6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ts_obj = pd.DataFrame(np.arange(start = start, stop = end + datetime.timedelta(hours = 1), step = datetime.timedelta(hours = 1)).astype(datetime.datetime), columns=[\"index\"])\n",
        "ts_obj  = ts_obj.merge(df.data, left_on = \"index\", right_on = \"period\", how=\"left\")"
      ],
      "id": "aea5caec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the Series\n",
        "\n",
        "We will use Plotly to visualize the series:\n"
      ],
      "id": "c615a962"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d = df.data.sort_values(by = [\"period\"])\n",
        "d = d[d[\"respondent\"] == \"US48\"]\n",
        "p = go.Figure()\n",
        "p.add_trace(go.Scatter(x = ts_obj[\"index\"], y = ts_obj[\"value\"],\n",
        "                       mode='lines',\n",
        "                    name='data',\n",
        "                    line=dict(color='royalblue', width=2)))\n",
        "p.show()"
      ],
      "id": "19ffb338",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Log and Check for Missing values\n"
      ],
      "id": "0a0c1aac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log = {\n",
        "    \"index\": 1,\n",
        "    \"respondent\": \"US48\",\n",
        "    \"respondent_type\": \"Demand\",\n",
        "    \"time\": datetime.datetime.now(),\n",
        "    \"start\": start,\n",
        "    \"end\": end,\n",
        "    \"start_act\": ts_obj[\"period\"].min(),\n",
        "    \"end_act\": ts_obj[\"period\"].max(),\n",
        "    \"start_match\": ts_obj[\"period\"].min() == start, \n",
        "    \"end_match\": ts_obj[\"period\"].max() == end, \n",
        "     \"n_obs\": len(ts_obj),\n",
        "    \"na\": ts_obj[\"value\"].isna().sum(),\n",
        "    \"type\": \"backfill\",\n",
        "    \"update\": False,\n",
        "    \"success\": False,\n",
        "    \"comments\": \"Initial data backfill\"\n",
        "\n",
        "}\n",
        "\n",
        "log_file = pd.DataFrame([log])\n",
        "\n",
        "log_file"
      ],
      "id": "ef386e72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Last but not least, we will check if the start and end of the series match the GET request settings and save the data and log:"
      ],
      "id": "da812857"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if (log_file.iloc[0][\"end\"] == log_file.iloc[0][\"end_act\"] and \n",
        "    log_file.iloc[0][\"start\"] == log_file.iloc[0][\"start_act\"] and\n",
        "    log_file.iloc[0][\"na\"] == 0):\n",
        "    log_file.loc[0, \"success\"] = True\n",
        "    print(\"Save the data into CSV file\")\n",
        "    df.data.to_csv(\"data/us48.csv\", index = False)\n",
        "    log_file.loc[0, \"update\"] = True\n",
        "    print(\"Save the metadata into CSV file\")\n",
        "    log_file.to_csv(\"data/us48_metadata.csv\", index = False)\n",
        "\n",
        "    \n",
        "else:\n",
        "    log_file.iloc[0][\"success\"] = False\n",
        "    log_file.iloc[0][\"update\"] = False"
      ],
      "id": "e81d6720",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Profiling\n",
        "\n",
        "The ydata-profiling library provides a detailed report about the data structure with the `ProfileReport` function:\n"
      ],
      "id": "b90bcb8e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "profile = ProfileReport(df.data, title=\"Profiling Report\")\n",
        "profile"
      ],
      "id": "a09a89c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create forecast\n"
      ],
      "id": "2dc7ce8e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = df.data\n",
        "data[\"period\"].max()"
      ],
      "id": "38cdcf07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "h = 24\n",
        "freq = 24\n",
        "num_samples = 500\n",
        "\n",
        "\n",
        "pd.read_csv(\"data/fc48_metadata.csv\")"
      ],
      "id": "53071e5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "start = 30\n",
        "\n",
        "for i in range(start, 0 , -1):\n",
        "    input = None\n",
        "    forecast = None\n",
        "    lon = None\n",
        "    print(i)\n",
        "    if i == start:\n",
        "        init = True\n",
        "    else:\n",
        "        init = False\n",
        "\n",
        "    end = data[\"period\"].max().floor(freq = \"d\") - datetime.timedelta(days = i) - datetime.timedelta(hours = 1)\n",
        "    start = end - datetime.timedelta(hours = freq * 365 * 2)\n",
        "    print(start, end)\n",
        "    input = fc.set_input(input = data, start = start, end = end)\n",
        "    print(input.forecast_start)\n",
        "    forecast = fc.train_lm(input = input, \n",
        "            lags = [ -freq, -7 * freq,  - 365 * freq],\n",
        "            likelihood = \"quantile\",\n",
        "            quantiles = [0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975],\n",
        "            h = h,\n",
        "            pi = 0.95,\n",
        "            num_samples = 500)\n",
        "    print(forecast.log)\n",
        "    log = fc.append_log(log_path= \"data/fc48_metadata.csv\", new_log = forecast.log, save = True, init = init)\n",
        "    new_fc = fc.append_forecast(fc_path =  \"data/fc48.csv\", fc_new = forecast, save = True, init = init)\n",
        "\n",
        "pd.read_csv(\"data/fc48_metadata.csv\")\n",
        "pd.read_csv(\"data/fc48.csv\")"
      ],
      "id": "2f13c815",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(pd.read_csv(\"data/fc48_metadata.csv\"))\n",
        "pd.read_csv(\"data/fc48.csv\")\n",
        "\n",
        "new_log = fc.score_forecast(log_path = \"data/fc48_metadata.csv\", actual = data, forecast = new_fc, save = True)\n",
        "new_log"
      ],
      "id": "afce5fe5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}