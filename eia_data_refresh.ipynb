{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: The US48 Deamnd for Electricity Data Pipeline\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "---"
      ],
      "id": "c56b94d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This doc run the data refresh process for the US48 demand for electricity dataset from the EIA API. It includes the following functionality:\n",
        "\n",
        "- Check if new data available on the API\n",
        "- Setting the data request parameters and pull the data\n",
        "- Data quality checks \n",
        "- Appending the new data and saving the data\n",
        "- Updating the log file \n",
        "\n",
        "## Load libraries\n",
        "\n",
        "We will pull the data from the EIA API using a set of functions on the `eia_api.py` file. This includes the following functions:\n",
        "\n",
        "- `eia_get` - A function for query data from the API. Can pull up to 5000 rows per call\n",
        "- `eia_backfile` - A wrapper function, using batches requests from the API using the `eia_get` function to serve large requests (more than 5000 rows)\n",
        "- `day_offset` - A helper function creates a vector of dates equally spaced by days\n",
        "- `hour_offset` - A helper function creates a vector of dates equally spaced by days\n",
        "\n",
        "The `eia_api.py` file imports the following libraries:\n",
        "\n",
        "- `pandas` - for data processing\n",
        "- `datetime` - to work with dates and time objects\n",
        "- `requests` - to send `GET` requests to the EIA API\n",
        "\n",
        "\n",
        "In addition, we will use the following libraries:\n",
        "\n",
        "- `os` - load environment variables\n",
        "- `numpy` - to create sequences (vectors)\n",
        "- `plotly` - visualize the data\n",
        "- `pathlib` - set file path\n",
        "- `ydata_profiling` - for data profiling\n"
      ],
      "id": "01208348"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load libraries\n",
        "import eia_api\n",
        "import eia_etl as etl\n",
        "import eia_forecast as fc_old\n",
        "import dev_fc as fc\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from statistics import mean\n",
        "from pathlib import Path\n",
        "from ydata_profiling import ProfileReport\n",
        "from zoneinfo import ZoneInfo\n",
        "from darts import TimeSeries\n",
        "from darts.models.forecasting.linear_regression_model import LinearRegressionModel"
      ],
      "id": "load-libraries",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Log File and API Metadata\n",
        "\n",
        "We will load the log file from the `data` folder:\n"
      ],
      "id": "b601f72b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_file = etl.load_log(path = \"data/us48_metadata.csv\")"
      ],
      "id": "71312cc7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `load_log` function returns the following objects:\n",
        "\n",
        "- `log` - the full data log\n",
        "- `last_success` - the log of the last success data pull\n",
        "- `end` - the timestamp of the last data point derived from the `last_success` row \n",
        "- `start` - the start timestamp of the future data pull (calculated as `end` + 1 hour)\n"
      ],
      "id": "fe841ee3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(log_file.last_success)\n",
        "print(log_file.end)\n",
        "print(log_file.start)\n",
        "\n",
        "start = log_file.start"
      ],
      "id": "d355dbc2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting the GET request parameters:\n"
      ],
      "id": "e6e21744"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "api_path = \"electricity/rto/region-data/data\"\n",
        "facets = {\n",
        "    \"respondent\": \"US48\",\n",
        "    \"type\": \"D\"\n",
        "}\n",
        "\n",
        "offset = 2250\n",
        "\n",
        "eia_api_key = os.getenv('EIA_API_KEY')"
      ],
      "id": "30c161da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pulling the series metadata from the API. We will use it to check if new data is available on the API using the `get_api_end` function:\n"
      ],
      "id": "55cef1d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metadata = etl.get_api_end(api_key = eia_api_key, \n",
        "api_path = \"electricity/rto/region-data/\", offset = 8)"
      ],
      "id": "2fe49409",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `end` variable represents the timestamp of the most recent data point available on the API. There is some issue on the API timestampe, a gap of 8 hours between the value of the last data point and the actual, therefore, we will offset the `end` value by 8 hours using the `offset` argument and save it as `end_fix`:\n"
      ],
      "id": "b6f03423"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(metadata.end)\n",
        "print(metadata.end_fix)\n",
        "\n",
        "end_fix = metadata.end_fix"
      ],
      "id": "2bf0ba95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_data = etl.eia_data_refresh(start = start, end = end_fix, api_key = eia_api_key, api_path = api_path, facets = facets, offset = 24 * 7) "
      ],
      "id": "9dfdb29a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Updating the Dataset and Log File\n"
      ],
      "id": "1aedea7b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "append_data = etl.append_new_data(data_path = \"data/us48.csv\",\n",
        "                           log_path = \"data/us48_metadata.csv\",\n",
        "                           new_data = new_data,\n",
        "                           save = True)\n",
        "\n",
        "data = append_data.data"
      ],
      "id": "74b8fdb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(append_data.log)\n",
        "print(append_data.data_update)"
      ],
      "id": "4a84470a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forecast Refresh\n",
        "\n",
        "Forecast scope:\n",
        "- Used a train forecasting model and refit it with new data\n",
        "- Forecast refresh daily at the end of the day (past 23:00 UTC)\n",
        "- Forecast horizon 24 hours\n",
        "\n",
        "Steps:\n",
        "- Load the forecast log file\n",
        "- Check the time stamp of the most recent forecast\n",
        "- Check if new data meet the refresh criteria\n",
        "- If meet the criteria, update the forecast\n",
        "- Update the log file\n",
        "\n",
        "\n",
        "\n",
        "Forecast parameters\n"
      ],
      "id": "af0efda9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "md_params = fc.model_params(model = \"LinearRegressionModel\",\n",
        "                    model_label = \"model 1\",\n",
        "                    comments = \"LM Model\",\n",
        "                    h = 24,\n",
        "                    lags = [-24, -7 * 24, - 365 * 24],\n",
        "                    freq = 24,\n",
        "                    pi = 0.95,\n",
        "                    train_length =  24 * 365 * 2,\n",
        "                    num_samples= 500,\n",
        "                    likelihood = \"quantile\",\n",
        "                    quantiles = [0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975],\n",
        "                    seed = 12345)  \n",
        "\n",
        "mlflow_settings = fc.mlflow_params(path = \"./metadata/\",\n",
        "                                experiment_name = \"Forecast Dev\",\n",
        "                                type = \"forecast\",\n",
        "                                score = False,\n",
        "                                append = False,\n",
        "                                version = \"0.0.1\")"
      ],
      "id": "9428f31e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_path = \"data/fc48_metadata.csv\"\n",
        "fc_path = \"data/fc48.csv\"\n",
        "\n",
        "forecast_start = data[\"period\"].max().floor(freq = \"d\")\n",
        "if os.path.isfile(log_path):\n",
        "    last_start = fc.get_last_fc_start(log_path = log_path)\n",
        "    create_new_fc = last_start < forecast_start\n",
        "else:\n",
        "    create_new_fc = True\n",
        "\n",
        "\n",
        "if create_new_fc:\n",
        "    print(\"Create new forecast\")\n",
        "    end = forecast_start - datetime.timedelta(hours = 1)\n",
        "    start = end - datetime.timedelta(hours = md_params.train_length)\n",
        "    print(start, end)\n",
        "    input = fc.set_input(input = data, start = start, end = end)\n",
        "    f = fc.forecast_object()\n",
        "    f.add_input(input = input) \n",
        "    f.add_model_params(model_params =  md_params)    \n",
        "    f.add_mlflow_settings(mlflow_settings = mlflow_settings)\n",
        "    f.create_forecast()\n",
        "\n",
        "    print(f.model_meta)\n",
        "    log = fc.append_log(log_path= log_path, new_log = f.model_meta, save = True, init = True)\n",
        "    new_fc = fc.append_forecast(fc_path =  fc_path, fc_new = f, save = True, init = True)"
      ],
      "id": "e2644253",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Score past forecasts\n"
      ],
      "id": "66f601b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "forecast_archive = fc_old.load_forecast(fc_path)\n",
        "new_log = fc_old.score_forecast(log_path = \"data/fc48_metadata.csv\", actual = data, forecast = forecast_archive, save = True)"
      ],
      "id": "219bd13c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}